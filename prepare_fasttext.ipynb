{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as sp \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import hstack\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from utils1 import *\n",
    "import string\n",
    "from pattern.en import suggest\n",
    "import snowballstemmer\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/train_tweets.txt\"\n",
    "temp = []\n",
    "with open(file, 'r') as data:\n",
    "    for line in data:\n",
    "        row = []\n",
    "        line = line.replace('\\t',\" \")\n",
    "        elem = line.strip().split(\" \")\n",
    "        row.append(elem[0])\n",
    "        row.append(\" \".join(elem[1:]))\n",
    "        temp.append(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def text_process(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_processed = tokenizer.tokenize(text)\n",
    "    text_processed = ' '.join(word for word in text_processed if word not in STOPWORDS)\n",
    "#     porter_stemmer = PorterStemmer()\n",
    "#     text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(tw):\n",
    "    tw[\"Tweet\"].replace(r'http.?://[^\\s]+[\\s]?','', regex=True,inplace=True)\n",
    "    tw['Tweet'] = tw['Tweet'].str.lower()\n",
    "    tw[\"Tweet\"].replace(r\"@\\S+\", \" \", regex=True ,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"(\\d{1,2})[/.-](\\d{1,2})[/.-](\\d{2,4})+\", \"DATE\", regex=True,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"(\\d{1,2})[/:](\\d{2})[/:](\\d{2})?(am|pm)+\", \"TIME\", regex=True,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"(\\d{1,2})[/:](\\d{2})?(am|pm)+\", \"TIME\", regex=True,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"\\d+\", \"NUM\", regex=True,inplace=True)\n",
    "    tw[\"Tweet\"].replace('[^a-zA-Z\\s]', '', regex=True,inplace=True)\n",
    "    tw['num_of_words'] = tw[\"Tweet\"].str.split().apply(len)\n",
    "    tw.drop(tw[tw.num_of_words<3].index, inplace=True)\n",
    "    return tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = pd.DataFrame(temp,columns = [\"User\",\"Tweet\"])\n",
    "tw = clean_df(tw)\n",
    "tw['Tweet'] = tw[\"Tweet\"].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_user(user):\n",
    "    user = f'__label__{user}'\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw['User'] = tw['User'].apply(rename_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>num_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134123</th>\n",
       "      <td>__label__9949</td>\n",
       "      <td>definately want</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209106</th>\n",
       "      <td>__label__4925</td>\n",
       "      <td>truthout revealed war fraud whistleblowers wra...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117889</th>\n",
       "      <td>__label__4893</td>\n",
       "      <td>flues dont even fireplace</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175905</th>\n",
       "      <td>__label__5729</td>\n",
       "      <td>haha looking buried booty ill leave another fa...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120782</th>\n",
       "      <td>__label__3494</td>\n",
       "      <td>really love coffee glad whoever invented</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223958</th>\n",
       "      <td>__label__7832</td>\n",
       "      <td>red ring killer youre screwed man thats got ri...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159409</th>\n",
       "      <td>__label__2828</td>\n",
       "      <td>start premiership today already good games exc...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315423</th>\n",
       "      <td>__label__2226</td>\n",
       "      <td>ever get feeling life comedy act world audience</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179499</th>\n",
       "      <td>__label__67</td>\n",
       "      <td>sf aka favorite american city place im destine...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185080</th>\n",
       "      <td>__label__337</td>\n",
       "      <td>hmm inspire craft tofunicorn</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 User                                              Tweet  \\\n",
       "134123  __label__9949                                    definately want   \n",
       "209106  __label__4925  truthout revealed war fraud whistleblowers wra...   \n",
       "117889  __label__4893                          flues dont even fireplace   \n",
       "175905  __label__5729  haha looking buried booty ill leave another fa...   \n",
       "120782  __label__3494           really love coffee glad whoever invented   \n",
       "223958  __label__7832  red ring killer youre screwed man thats got ri...   \n",
       "159409  __label__2828  start premiership today already good games exc...   \n",
       "315423  __label__2226    ever get feeling life comedy act world audience   \n",
       "179499    __label__67  sf aka favorite american city place im destine...   \n",
       "185080   __label__337                       hmm inspire craft tofunicorn   \n",
       "\n",
       "        num_of_words  \n",
       "134123             4  \n",
       "209106            11  \n",
       "117889             7  \n",
       "175905            15  \n",
       "120782            13  \n",
       "223958            14  \n",
       "159409            17  \n",
       "315423            17  \n",
       "179499            14  \n",
       "185080             8  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.sample(10,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tw.Tweet,tw.User, random_state=0,test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(X,y,filename):\n",
    "    with open(filename, 'w') as writeFile:\n",
    "        for user,tweet in zip(y,X):\n",
    "            writeFile.write(f'{user} {tweet}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(X_train,y_train,'trainData.train')\n",
    "write_file(X_test,y_test,'testData.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(\n",
    "    input=\"trainData.train\", \n",
    "    lr=0.2, \n",
    "    epoch=25, \n",
    "    wordNgrams=2, \n",
    "    bucket=200000, \n",
    "    dim=100, \n",
    "    loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
