{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as sp \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import hstack\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from utils1 import *\n",
    "import string\n",
    "from pattern.en import suggest\n",
    "import snowballstemmer\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/train_tweets.txt\"\n",
    "temp = []\n",
    "with open(file, 'r') as data:\n",
    "    for line in data:\n",
    "        row = []\n",
    "        line = line.replace('\\t',\" \")\n",
    "        elem = line.strip().split(\" \")\n",
    "        row.append(elem[0])\n",
    "        row.append(\" \".join(elem[1:]))\n",
    "        temp.append(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and data manipulation\n",
    "\n",
    "    Currently removing stop-words, lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_no_tweets = 5\n",
    "threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def text_process(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_processed = tokenizer.tokenize(text)\n",
    "    text_processed = ' '.join(word for word in text_processed if word not in STOPWORDS)\n",
    "#     porter_stemmer = PorterStemmer()\n",
    "#     text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(tw):\n",
    "    tw[\"Tweet\"].replace(r'http.?://[^\\s]+[\\s]?','', regex=True,inplace=True)\n",
    "    tw['Tweet'] = tw['Tweet'].str.lower()\n",
    "    tw[\"Tweet\"].replace(r\"@\\S+\", \" \", regex=True ,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"(\\d{1,2})[/.-](\\d{1,2})[/.-](\\d{2,4})+\", \"DATE\", regex=True,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"(\\d{1,2})[/:](\\d{2})[/:](\\d{2})?(am|pm)+\", \"TIME\", regex=True,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"(\\d{1,2})[/:](\\d{2})?(am|pm)+\", \"TIME\", regex=True,inplace=True)\n",
    "#     tw[\"Tweet\"].replace(r\"\\d+\", \"NUM\", regex=True,inplace=True)\n",
    "    tw[\"Tweet\"].replace('[^a-zA-Z\\s]', '', regex=True,inplace=True)\n",
    "    tw['num_of_words'] = tw[\"Tweet\"].str.split().apply(len)\n",
    "    tw.drop(tw[tw.num_of_words<4].index, inplace=True)\n",
    "    return tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = pd.DataFrame(temp,columns = [\"User\",\"Tweet\"])\n",
    "tw = clean_df(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_user = tw['User'].value_counts()\n",
    "cnt_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw.sample(10,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "    Using TF-IDF and without sampling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cnt_user)\n",
    "top_user = df[df['User'] >= min_no_tweets].index.tolist()\n",
    "top_k = tw[tw.User.isin(top_user)]\n",
    "data = top_k['User'].value_counts()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet = top_k.groupby('User',group_keys=False).apply(lambda x: x.sample(n = min(threshold,len(x))))\n",
    "Tweet.sample(10,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Tweet[\"User\"].value_counts()\n",
    "print(vis.describe())\n",
    "print(Tweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_features(data):\n",
    "    w1 = word1_v.transform(data)\n",
    "    w2 = word2_v.transform(data)\n",
    "    w3 = word3_v.transform(data)\n",
    "    c1 = char_v.transform(data)\n",
    "    stack = hstack([w1,w2,w3,c1])\n",
    "    stack = preprocessing.normalize(stack)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1_v = TfidfVectorizer(ngram_range = (1,1), min_df = 3, sublinear_tf = True, max_df = .75, tokenizer= text_process, max_features =20000)\n",
    "word2_v = TfidfVectorizer(ngram_range = (2,2), min_df = 3, sublinear_tf = True, max_df = .75, tokenizer= text_process, max_features =20000)\n",
    "word3_v = TfidfVectorizer(ngram_range = (3,3), min_df = 3, sublinear_tf = True, max_df = .75, tokenizer= text_process, max_features =20000)\n",
    "char_v = TfidfVectorizer(analyzer='char', ngram_range=(2,4), sublinear_tf = True, max_df = .75, tokenizer= text_process, max_features = 20000)\n",
    "word1_v.fit(Tweet.Tweet)\n",
    "word2_v.fit(Tweet.Tweet)\n",
    "word3_v.fit(Tweet.Tweet)\n",
    "char_v.fit(Tweet.Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Tweet.Tweet\n",
    "y = Tweet.User\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,test_size = .3)\n",
    "X_train = stack_features(X_train)\n",
    "X_test = stack_features(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various O vs R classifiers Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "lr = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "svm = LinearSVC(max_iter=5000)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20, max_features=5000,n_jobs=-1)\n",
    "\n",
    "def test_model(model):\n",
    "    if model == 'LR':\n",
    "        fit = lr.fit(X_train, y_train)\n",
    "        algorithm = 'Logistic Regression'\n",
    "    if model == 'MNB':\n",
    "        fit = nb.fit(X_train, y_train)\n",
    "        algorithm = 'Multinomial Naive Bayes'\n",
    "    if model == 'SVC':\n",
    "        fit = svm.fit(X_train, y_train)\n",
    "        algorithm = 'Linear SVC'   \n",
    "    if model == 'RF':\n",
    "        fit = rf.fit(X_train, y_train)\n",
    "        algorithm = 'Random Forest'\n",
    "    print(algorithm)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = test_model('SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- One Vs Rest --\")\n",
    "# print(\"Weighted F1: {0}\".format(metrics.f1_score(y_test, preds, average=scoring_average)))\n",
    "# print(\"Precision: {0}\".format(metrics.precision_score(y_test, preds, average=scoring_average)))\n",
    "# print(\"Recall: {0}\".format(metrics.recall_score(y_test, preds, average=scoring_average)))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('sampl', SMOTEENN()), \n",
    "                 ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ovr = OneVsRestClassifier(pipe)\n",
    "ovr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = ovr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- One Vs Rest --\")\n",
    "print(\"Weighted F1: {0}\".format(metrics.f1_score(y_test, preds, average=scoring_average)))\n",
    "print(\"Precision: {0}\".format(metrics.precision_score(y_test, preds, average=scoring_average)))\n",
    "print(\"Recall: {0}\".format(metrics.recall_score(y_test, preds, average=scoring_average)))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skdist.distribute.search import DistGridSearchCV\n",
    "from pyspark.sql import SparkSession \n",
    "from skdist.distribute.multiclass import DistOneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.executor.memory\", \"70g\") \\\n",
    "     .config(\"spark.driver.memory\", \"50g\") \\\n",
    "     .config(\"spark.memory.offHeap.enabled\",true) \\\n",
    "     .config(\"spark.memory.offHeap.size\",\"16g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1.0, 10.0],  \n",
    "    \"max_iter\" : [1000,3000,5000]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = DistOneVsRestClassifier(LinearSVC(max_iter = 1000), sc)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- One Vs Rest --\")\n",
    "print(\"Weighted F1: {0}\".format(metrics.f1_score(y_test, preds, average=scoring_average)))\n",
    "print(\"Precision: {0}\".format(metrics.precision_score(y_test, preds, average=scoring_average)))\n",
    "print(\"Recall: {0}\".format(metrics.recall_score(y_test, preds, average=scoring_average)))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "# print(pickle.loads(pickle.dumps(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data():\n",
    "    file1 = \"data/test_tweets_unlabeled.txt\"\n",
    "    with open(file1, 'r') as data:\n",
    "        temp = [line for line in data]    \n",
    "    unlabel = pd.DataFrame(temp,columns = [\"Tweet\"])\n",
    "    unlabel = clean_df(unlabel)\n",
    "    unlabel = stack_features(unlabel)\n",
    "    return unlabel\n",
    "    \n",
    "def submission_file(data):\n",
    "    import csv\n",
    "    with open('predicted.csv', 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerow(['Id','Predicted'])\n",
    "        for count,predicted in enumerate(data):\n",
    "            writer.writerow([count+1,predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabel_data = prepare_test_data() \n",
    "unlabel_pred = model.predict(unlabel_data)\n",
    "submission_file(unlabel_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
